cat > README.md << 'EOF'
# Cricket Statistics Q&A System ðŸ

Fine-tuned LLM system for answering cricket match statistics questions using a multi-agent architecture with grounded answer extraction.

[![Python 3.10](https://img.shields.io/badge/python-3.10-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green.svg)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](https://www.docker.com/)
[![HuggingFace](https://img.shields.io/badge/ðŸ¤—-Model-yellow.svg)](https://huggingface.co/Conqueror00001/qwen-ipl-lora)

## ðŸŽ¯ Features

- **Multi-Agent Architecture**: Deterministic stats computation + LLM reasoning
- **Fine-tuned Model**: LoRA-adapted Qwen 0.5B optimized for cricket statistics
- **Grounded Answers**: Strict extraction prevents hallucinations
- **Lazy Loading**: Fast startup, model loads on-demand
- **Docker Ready**: One-command deployment
- **Sample Data**: Works out-of-box for testing

## ðŸ—ï¸ Architecture
```
User Question
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ StatsTool                         â”‚
â”‚ (Deterministic computation)       â”‚
â”‚ - Runs in last N overs            â”‚
â”‚ - Total runs/wickets              â”‚
â”‚ - Fours, sixes, etc.              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RetrieverAgent                    â”‚
â”‚ (Context generation)              â”‚
â”‚ - Formats stats as text           â”‚
â”‚ - Creates LLM-readable context    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AnalystAgent                      â”‚
â”‚ (LLM + Grounded extraction)       â”‚
â”‚ - Fine-tuned Qwen 0.5B            â”‚
â”‚ - LoRA adapters                   â”‚
â”‚ - Regex-based grounding           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Numeric Answer (grounded in context)
```

## ðŸš€ Quick Start

### Prerequisites

- Docker (recommended)
- OR Python 3.10+ with pip
- HuggingFace account ([create here](https://huggingface.co/join))

### Option 1: Docker (Recommended)
```bash
# 1. Get HuggingFace token
# Visit: https://huggingface.co/settings/tokens
# Create token with "Read" permission
export HF_TOKEN="hf_your_token_here"

# 2. Build image
docker build -t cricket-qa:latest -f service/Dockerfile .

# 3. Run container
docker run -d \
  -p 8000:8000 \
  -e HF_TOKEN="$HF_TOKEN" \
  --name cricket-qa \
  cricket-qa:latest

# 4. Test (first request takes 2-5 min to load model)
curl -X POST http://localhost:8000/infer \
  -H "Content-Type: application/json" \
  -d '{"question": "How many runs in the last 5 overs?"}'
```

### Option 2: Local Development
```bash
# 1. Clone repository
git clone https://github.com/YOUR_USERNAME/cricket-qa-system.git
cd cricket-qa-system

# 2. Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Set environment variables
export HF_TOKEN="hf_your_token_here"

# 5. Run service
uvicorn service.app:app --host 0.0.0.0 --port 8000

# 6. Test in another terminal
curl -X POST http://localhost:8000/infer \
  -H "Content-Type: application/json" \
  -d '{"question": "How many wickets were taken?"}'
```

## ðŸ“Š Sample Data

Included sample data (`data/sample_match.json`):
- **30 cricket events** across 5 overs
- **Total runs**: 47
- **Wickets**: 3
- **Fours**: 4
- **Sixes**: 3

Perfect for testing without real match data.

## ðŸ”§ API Endpoints

### `GET /healthz`
Health check (always responds immediately)
```bash
curl http://localhost:8000/healthz
```
Response: `{"status": "ok"}`

### `GET /readyz`
Readiness check (returns true after model loads)
```bash
curl http://localhost:8000/readyz
```
Response: `{"ready": true, "loading": false}`

### `POST /infer`
Main inference endpoint

**Request:**
```json
{
  "question": "How many runs in the last 5 overs?",
  "max_tokens": 100,
  "commentary": {
    "commentaries": [
      {"event": "ball", "over": 1, "run": 4, "four": true, "six": false},
      ...
    ]
  }
}
```

**Response:**
```json
{
  "answer": "47",
  "context_used": "Context:\n- Total runs: 47\n- Runs in last 5 overs: 47...",
  "status": "success"
}
```

**Note**: `commentary` is optional. If not provided, uses default sample data.

## ðŸ“ Project Structure
```
cricket-qa-system/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ multi_agent.py          # StatsTool, RetrieverAgent, AnalystAgent
â”œâ”€â”€ service/
â”‚   â”œâ”€â”€ app.py                  # FastAPI service (lazy loading)
â”‚   â””â”€â”€ Dockerfile              # Docker configuration
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py                 # Alternative API entrypoint
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_sft.py            # LoRA training script
â”‚   â”œâ”€â”€ prepare_dataset.py      # Data preparation
â”‚   â””â”€â”€ generate_qa.py          # QA pair generation
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_inference.py       # Pytest tests
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_match.json       # Demo data (included)
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example                # Environment variables template
â”œâ”€â”€ .gitignore                  # Git ignore rules
â”œâ”€â”€ LICENSE                     # MIT License
â””â”€â”€ README.md                   # This file
```

## ðŸ¤– Model Details

- **Base Model**: [Qwen/Qwen2.5-0.5B-Instruct](https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct)
- **Fine-tuning**: LoRA (Low-Rank Adaptation) via PEFT
- **Adapter Repo**: [Conqueror00001/qwen-ipl-lora](https://huggingface.co/Conqueror00001/qwen-ipl-lora)
- **Training**: Supervised fine-tuning on cricket Q&A pairs
- **Grounding**: Strict numeric extraction (only returns numbers present in context)
- **Device**: CPU/MPS (Apple Silicon) compatible

## ðŸ”’ Using Your Own Data

### Data Format

Your cricket commentary data should follow this JSON structure:
```json
{
  "commentaries": [
    {
      "event": "ball",
      "over": 1,
      "run": 4,
      "four": true,
      "six": false
    },
    {
      "event": "wicket",
      "over": 2,
      "run": 0,
      "four": false,
      "six": false
    }
  ]
}
```

### Option 1: Environment Variable
```bash
export DEFAULT_MATCH_FILE="/path/to/your/match.json"
uvicorn service.app:app --host 0.0.0.0 --port 8000
```

### Option 2: Docker Volume Mount
```bash
docker run -d \
  -p 8000:8000 \
  -e HF_TOKEN="$HF_TOKEN" \
  -e DEFAULT_MATCH_FILE="/data/your_match.json" \
  -v /path/on/host:/data \
  cricket-qa:latest
```

### Option 3: Request Body

Include commentary directly in API request:
```bash
curl -X POST http://localhost:8000/infer \
  -H "Content-Type: application/json" \
  -d '{
    "question": "How many runs?",
    "commentary": {
      "commentaries": [...]
    }
  }'
```

## ðŸ§ª Testing
```bash
# Run tests
pytest tests/

# Specific test
pytest tests/test_inference.py -v

# With coverage
pytest --cov=agents --cov=service tests/
```

## ðŸŽ“ Training Your Own Model

If you want to train on your own cricket data:
```bash
# 1. Prepare dataset
python scripts/prepare_dataset.py

# 2. Generate Q&A pairs
python scripts/generate_qa.py

# 3. Train LoRA adapters
python scripts/train_sft.py

# 4. Upload to HuggingFace (optional)
python scripts/upload_to_hf.py
```

**Note**: Training data not included in this repo. You'll need your own cricket commentary data.

## ðŸ› Troubleshooting

### Model Loading Fails
```
Error: Can't find 'adapter_config.json'
```
**Solution**: Verify HF_TOKEN is set and has read access:
```bash
echo $HF_TOKEN
hf auth whoami
```

### Port Already in Use
```
Error: Address already in use
```
**Solution**: Use different port:
```bash
docker run -p 8001:8000 ...  # Use 8001 instead
```

### First Request Timeout
First request takes 2-5 minutes to download model (~500MB). Subsequent requests are instant (<1s).

### Wrong Answers
The model is grounded to only return numbers from context. If context doesn't contain the answer, it returns "The information is not available in the provided data."

## ðŸ“ License

MIT License - see [LICENSE](LICENSE) file for details.

## ðŸ™ Acknowledgments

- **Base Model**: Qwen by Alibaba Cloud
- **Fine-tuning**: PEFT library by HuggingFace
- **Framework**: FastAPI by Tiangolo

## ðŸ”— Links

- [HuggingFace Model](https://huggingface.co/Conqueror00001/qwen-ipl-lora)
- [Base Model (Qwen)](https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct)
- [FastAPI Docs](https://fastapi.tiangolo.com/)
- [PEFT Library](https://github.com/huggingface/peft)

## ðŸ“§ Questions?

Open an issue on GitHub or reach out via HuggingFace discussions.

---

**Built with â¤ï¸ for cricket analytics**
